{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Văn bản #1:\n",
      "Top chủ đề: [0 3 1]\n",
      "\n",
      "Văn bản #2:\n",
      "Top chủ đề: [4 1 0]\n",
      "\n",
      "Văn bản #3:\n",
      "Top chủ đề: [0 1 4]\n",
      "\n",
      "Văn bản #4:\n",
      "Top chủ đề: [1 2 4]\n",
      "\n",
      "Văn bản #5:\n",
      "Top chủ đề: [0 2 4]\n",
      "\n",
      "Văn bản #6:\n",
      "Top chủ đề: [2 3 1]\n",
      "\n",
      "Văn bản #7:\n",
      "Top chủ đề: [1 2 4]\n",
      "\n",
      "Văn bản #8:\n",
      "Top chủ đề: [0 4 2]\n",
      "\n",
      "Văn bản #9:\n",
      "Top chủ đề: [2 4 1]\n",
      "\n",
      "Văn bản #10:\n",
      "Top chủ đề: [1 0 4]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import re\n",
    "\n",
    "def read_and_process(filename):\n",
    "    \"\"\"\n",
    "    Đọc file txt, xử lý dữ liệu và trả về kết quả.\n",
    "    Returns:\n",
    "        list: Danh sách các văn bản đã được xử lý.\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = f.readlines()\n",
    "    \n",
    "    processed_data = []\n",
    "    for line in data:\n",
    "        # Tiền xử lý văn bản: loại bỏ ký tự đặc biệt và chuyển về chữ thường\n",
    "        line = re.sub(r\"[^\\w\\s]\", \"\", line)\n",
    "        line = line.lower().strip()\n",
    "        processed_data.append(line)\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "filename_train = \"3.topic_detection_train.v1.0.txt\"\n",
    "filename_test = \"3.topic_detection_test.v1.0.txt\"\n",
    "\n",
    "# Đọc và xử lý dữ liệu từ tập train\n",
    "processed_data_train = read_and_process(filename_train)\n",
    "processed_data_test = read_and_process(filename_test)\n",
    "\n",
    "# Biểu diễn văn bản bằng Bag of Words từ tập train\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(processed_data_train)\n",
    "\n",
    "# Áp dụng mô hình LDA để tìm các chủ đề trên tập train\n",
    "num_topics = 5  # Số lượng chủ đề cần tìm\n",
    "lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda.fit(X_train)\n",
    "\n",
    "# Biểu diễn văn bản từ tập test bằng Bag of Words\n",
    "X_test = vectorizer.transform(processed_data_test)\n",
    "\n",
    "# Dự đoán các chủ đề cho các văn bản trong tập test\n",
    "topic_predictions = lda.transform(X_test)\n",
    "\n",
    "# In ra các chủ đề dự đoán cho một số văn bản trong tập test\n",
    "for i in range(10):  # In ra 10 dự đoán đầu tiên\n",
    "    top_topics = topic_predictions[i].argsort()[:-3 - 1:-1]  # Lấy 3 chủ đề có xác suất cao nhất\n",
    "    print(f\"Văn bản #{i + 1}:\")\n",
    "    print(f\"Top chủ đề: {top_topics}\")\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chủ đề #1:\n",
      "cho có phòng nhà và giá nước bạn để vào\n",
      "\n",
      "Chủ đề #2:\n",
      "là của và có bạn những một không người được\n",
      "\n",
      "Chủ đề #3:\n",
      "học và các có của là trong được không cho\n",
      "\n",
      "Chủ đề #4:\n",
      "số ăn bánh bà đi em hai hoàn kiếm mình\n",
      "\n",
      "Chủ đề #5:\n",
      "công hàng doanh các và có thuế của toán số\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In ra các từ khóa của từng chủ đề\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Chủ đề #{topic_idx + 1}:\")\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-10 - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đây là một ví dụ về URL:  và  nhe ban\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def remove_http_phrases(text):\n",
    "    # Biểu thức chính quy để tìm các cụm từ bắt đầu bằng \"http\"\n",
    "    http_pattern = re.compile(r'http\\S*')\n",
    "    # Thay thế các cụm từ bằng chuỗi rỗng\n",
    "    return http_pattern.sub(r'', text)\n",
    "\n",
    "# Ví dụ sử dụng hàm với một chuỗi văn bản\n",
    "sample_text = \"Đây là một ví dụ về URL: http://example.com và https://example.com nhe ban\"\n",
    "cleaned_text = remove_http_phrases(sample_text)\n",
    "print(cleaned_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
